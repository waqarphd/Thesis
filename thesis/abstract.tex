% ************************** Thesis Abstract *****************************
%\documentclass{article}
%\usepackage{graphicx}

%\begin{document}
% Use abstract' as an option in the document class to print only the title page and the abstract.
%@@@@@@@@@@@@@@@@@@@
% Introduction
% @@@@@@@@@@@@@@@@@@@
\begin{abstract}
The data acquisition (DAQ) system of any particle physics experiment consists in the set of components, hardware and software, responsible of recording, transmitting and storing all the experiment data for future offline analysis. Often the DAQ system cannot record the data of every eventÄù or collision happening in the experiment and therefore requires an online selection to reduce the data volume. This selection is provided by the trigger system which asserts the data acquisition only if the data fulfil pre-defined criteria. Together they form the trigger and data acquisition system (TDAQ), responsible to collect in a few milliseconds all the data recorded by the millions of electronic channels of the experiment, and to transmit them without alteration towards processors. There, the data are analysed in a Äúreal timeÄù (~1s) and potentially selected to be archived on magnetic support. All these actions should be performed with high fidelity to insure the integrity of the data that will be interpreted offline by the physicists.

Modern technologies allow to design the physical architecture of the TDAQ system independently from the detector to which it will be connected, the specificity of the detectors and the physics are ported in programmable logic electronics nowadays mainly composed of commercial Field-Programmable Gate Arrays (FPGA). The FPGA provides the facility for change in the function of the electronics, even after the underlying hardware has been manufactured, while significantly reducing development time.¬† Together with FPGAs, it becomes clear now that the future particle and astro-particle experiments plan to use the most advanced technologies from the telecommunication and the digital programmable electronic industries: the Advanced Telecom Computing Architecture (ATCA or micro-TCA) standard.

This thesis focuses on the design, the development and the implementation of the TDAQ system of the CMS Forward Muon Upgrade project which proposes to install Triple-GEM detectors instead of Resistive Plate Chambers in the CMS muon station at 1.6 <$\eta$< 2.4 during the 2nd LHC long shutdown. This work has been performed in close collaboration with the Inter-University Institutes for High Energies (IIHE ULB-VUB) of Brussels (Belgium).

In the framework of the CMS upgrades, the IIHE is investigating the new micro-TCA standard, introduced by the telecommunication industry, to replace the VME electronics. With its high data throughput (several Gbps), high reliability and high availability, the micro-TCA standard combined with the most powerful FPGAs for the data processing should allow the future CMS DAQ system to cope with the LHC luminosity beyond the nominal value of 10$^{33}$ cm$^{-2}$s$^{-1}$. Typically these systems require high data volume transmission, from 0.5 to 3.2 Gbps, from the detector to off-detector electronics where data are processed by FPGAs, as well as the distribution of precise signals like clock and trigger inputs towards the detectors. The high bandwidth transmission uses optical fibre transceivers and gigabit transceiver blocks (GTPs) routinely built into FPGA devices.

The hardware and firmware solutions for the synchronization of the chamber data and transmission channels were created by the main developer of the firmware for the PAC system Yifan young. My tasks was to find the ways of using those solutions in practice. I have worked out the methods for finding the optimal values of the synchronization parameters and implemented them in the dedicated software procedures, which allowed successful synchronization  of the VFAT signal to optohybrid module. (at the moment for the cosmic muons). I am also work on test GEM with optohybrid (OH-v1) and OH-v2.
%@@@@@@@@@@@@@@@@@@@
% Overview
% @@@@@@@@@@@@@@@@@@@
The main and key responsibility to develop Detector control system for new GEM for Cosmic test in TIF lab, test beam analysis and for slice test in P5. There are three DCS main system to develop and test with real system. The main and difficult part of the project develop new Finite State Machine (FSM). All system are move around the DCS like interface between one system to other subsystem generate alert,and integrate other system. 

DAQ is one of the primary part of the project  There are two way to exchange the data between DCS and XDAQ.  if the amount of the data is huge then we will use DIP system provided in the DCS. The other tool is PSX , it is a system which allows relatively small amounts of data to be exchanged between XDAQ client applications and DCS systems. It is assumed that these client application do not need very low latency and high rate. The data is assumed to be mostly summarized data rather than low-level parameters from the individual systems. The PSX services are meant to be used for status analysis only and therefore are considered as non critical. 

Testing setup hodoscope is also major part of the project, I am also involved in development of 


\end{abstract}

%\end{document}
